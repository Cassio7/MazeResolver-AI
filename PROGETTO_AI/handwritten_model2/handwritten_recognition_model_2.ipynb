{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1tMT2jwhDx6XCvVJWL60wpv71mSYCM-Ni","timestamp":1694876288779}],"authorship_tag":"ABX9TyNAyJEbBtVYmbWTVFLIIoen"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x91DOCbuv47K","executionInfo":{"status":"ok","timestamp":1694876578922,"user_tz":-120,"elapsed":17885,"user":{"displayName":"Davide Civicchioni","userId":"09524019923032056891"}},"outputId":"05105a08-5ba6-47c2-d5ec-eca40c5d523b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install emnist"],"metadata":{"id":"72TySlEvwD7X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten, Dropout\n","from tensorflow.keras.utils import to_categorical\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","\n","import numpy as np\n","\n","import random\n","\n","from matplotlib import pyplot as plt\n","\n","from emnist import list_datasets\n","from emnist import extract_training_samples\n"],"metadata":{"id":"WXrpU93cv2Po"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cKDGB73fuOxO"},"outputs":[],"source":["# carica il dataset emnist\n","images, labels = extract_training_samples('byclass')\n","\n","# Stampa i primi 10 elementi\n","# for i in range(10):\n","#     print(f'Immagine {i+1}:')\n","#     print(images[i])  # Stampa l'array dell'immagine\n","#     print(f'Label {i+1}: {labels[i]}')  # Stampa la label corrispondente\n","#     print('---------------------------------')"]},{"cell_type":"code","source":["# Stampa info sul dataset\n","print(\"Images shape:\", images.shape)\n","print(\"Labels shape:\", labels.shape)\n","print(\"Unique labels:\", np.unique(labels).shape[0])\n","print(\"Number of unique labels:\", len(np.unique(labels)))\n","\n","# prendo solo le immagini dei caretteri che mi interessano da tutto il dataset di emnist\n","\n","# 0: 0\n","# 1: 1\n","# 2: 2\n","# 3: 3\n","# 4: 4\n","# 14: E\n","# 28: S\n","# 33: X\n","# 54: s\n","# 59: x\n","\n","#my_labels=[0, 1, 2, 3, 4, 14, 28, 33, 54, 59] # vengono salvati le labels dei caratteri: 'S', 'E', 'X', '0', '1', '2', '3', '4' (con s & x piccole e grandi)\n","#lookup = { '0': 0, '1':1, '2':2, '3':3, '4':4, '14':5, '28':6, '33': 7, '54':8, '59':9 } # nuove labels assegnate ad ogni carattere\n","#my_labels=[0, 1, 2, 3, 4, 14, 28, 33] # vengono salvati le labels dei caratteri: 'S', 'E', 'X', '0', '1', '2', '3', '4'\n","#lookup = { '0': 0, '1':1, '2':2, '3':3, '4':4, '14':5, '28':6, '33': 7} # nuove labels assegnate ad ogni carattere\n","my_labels=[1, 2, 3, 4, 14, 28, 33] # vengono salvati le labels dei caratteri: 'S', 'E', 'X', '0', '1', '2', '3', '4'\n","lookup = {'1':0, '2':1, '3':2, '4':3, '14':4, '28':5, '33': 6} # nuove labels assegnate ad ogni carattere\n","\n","indices=[]\n","new_images=[]\n","new_labels=[]\n","\n","for i in range(len(labels)):\n","  if labels[i] in my_labels:\n","    indices.append(i) # salvo gli indici di tutte le rappresentazioni in emnist del carattere con label in 'my_labels'\n","\n","# nello specifico: in emnist esistono diverse rappresentazioni dello stesso carattere (ipoteticamente, una per ogni modo in cui è possibile scrivere quel carattere a mano)\n","# Ognuna ha la stessa label. Quindi, facendo una ricerca per labels all'interno del dataset ottengo tutte le rappresentazioni(immagini) di quel carattere.\n","\n","for j in range(len(indices)):\n","  new_images.append(images[indices[j]])\n","  new_labels.append(lookup[str(labels[indices[j]])])\n","\n","# converto images_i e labels_i da list a np_array e sovrascrivo le vecchie variabili\n","# new_images sarà composto sia dalle immagini selezionate da emnist che dalle immagini del dataset artificiale\n","# new_images = np.concatenate((art_images, new_images), axis=0)\n","# new_labels = np.concatenate((art_labels, new_labels), axis=0)\n","new_images = np.array(new_images)\n","new_labels = np.array(new_labels)\n","\n","print(\"Images shape:\", new_images.shape)\n","print(\"Labels shape:\", new_labels.shape)\n","print(\"Unique labels:\", np.unique(new_labels).shape[0])\n","print(\"Number of unique labels:\", len(np.unique(new_labels)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cp7fyvMOuk4y","executionInfo":{"status":"ok","timestamp":1694876802170,"user_tz":-120,"elapsed":7457,"user":{"displayName":"Davide Civicchioni","userId":"09524019923032056891"}},"outputId":"36904e66-5b44-4c6d-f8f5-ac3cb9177955"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Images shape: (697932, 28, 28)\n","Labels shape: (697932,)\n","Unique labels: 62\n","Number of unique labels: 62\n","Images shape: (169724, 28, 28)\n","Labels shape: (169724,)\n","Unique labels: 7\n","Number of unique labels: 7\n"]}]},{"cell_type":"code","source":["# Plot some sample images\n","num_samples_to_plot = 50\n","num_rows = num_samples_to_plot // 10\n","num_cols = 10\n","\n","plt.figure(figsize=(15, 15))  # Regolato il figsize per una migliore visualizzazione\n","\n","for i in range(num_samples_to_plot):\n","    plt.subplot(num_rows, num_cols, i + 1)  # Configura la posizione del sottoplot\n","    plt.imshow(new_images[i])  # Utilizzo cmap='gray' per le immagini in scala di grigi\n","    plt.title(f'{new_labels[i]}')\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.grid(False)\n","    plt.axis('off')\n","\n","plt.tight_layout()  # Aggiunge il layout compatto tra i sottoplot\n","plt.show()"],"metadata":{"id":"9we6NCxGunMX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Normalize images to the range [0, 1]:\n","# calcola i valori minimi e massimi presenti nei dati, quindi normalizza i valori dei pixel in modo che siano nell'intervallo [0, 1].\n","# Alla fine dell'esecuzione di questo codice, images_normalized conterrà le immagini normalizzate, dove i valori dei pixel sono scalati nell'intervallo [0, 1].\n","feature_vector_length = 784\n","#scaler = MinMaxScaler()\n","#images_normalized = scaler.fit_transform(images.reshape(-1, feature_vector_length)) # le immagini vengono trasformate da una matrice 3D (28*28*1) a una 2D (784*1).\n","# Questo passaggio è necessario perchè MinMaxScaler lavora con matrici bidimensionali\n","\n","images_normalized = new_images.astype(\"float32\")/255\n","new_labels = new_labels.astype(\"float32\")\n","#print(images_normalized[0])\n","\n","#images_normalized = images_normalized.reshape(-1, 28, 28, 1) # le immagini vengono ripristinate alla forma di partenza 3D (28*28*1) - può anche non essere fatto\n","\n","print(\"max pixel values : \",np.max(images_normalized))\n","print(\"min pixel values: \",np.min(images_normalized))\n","\n","# Split dataset into training and testing sets\n","train_images, test_images, train_labels, test_labels = train_test_split(\n","    images_normalized, new_labels, test_size=0.34, random_state=100\n",") # test_size è la proporzioni di dati da allocare per il test_set (20%).\n","# random_state imposta il seed per il generatore di numeri casuali\n","\n","print(train_images.shape)\n","print(train_labels.shape)"],"metadata":{"id":"f5JggeRduvoE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Build the ANN model\n","model = keras.Sequential([\n","    Flatten(input_shape=(28, 28, 1)),\n","    Dense(256, activation='relu'),  # Aumenta il numero di unità\n","    Dropout(0.5),  # Aggiungi dropout per prevenire l'overfitting\n","    Dense(128, activation='relu'),\n","    Dropout(0.5),\n","    Dense(len(np.unique(labels)), activation='softmax')\n","])\n","\n","model.summary()\n","\n","# Compile the model\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Train the model\n","batch_size = 128 # 128\n","epochs = 7\n","model.fit(train_images, train_labels, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n","# batch_size: durante ogni ciclo di addestramento verranno prese 128 immagini e le relative etichette alla volta per calcolare un aggiornamento dei pesi della rete.\n","# epochs = 1: indica che il modello verrà addestrato per un solo ciclo completo attraverso tutti i dati di addestramento.\n","# validation_split=0.1: indica che il 10% dei dati di addestramento verrà utilizzato come set di convalida per monitorare le prestazioni del modello durante l'addestramento.\n","\n","# Evaluate the model on the test set\n","score = model.evaluate(test_images, test_labels, verbose=0)\n","print(f\"Test loss: {score[0]}\\nTest Accuracy: {score[1]}\")\n","\n","model.save(\"/content/drive/MyDrive/Colab Notebooks/PROGETTO_AI/handwritten_model2\")\n"],"metadata":{"id":"GunbXKW8uzp5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Scegli un numero casuale di immagini da testare\n","num_images_to_test = 10\n","\n","# Estrai casualmente un insieme di indici delle immagini dal set di test\n","random_image_indices = random.sample(range(len(test_images)), num_images_to_test)\n","\n","# Loop attraverso le immagini selezionate casualmente\n","for i in random_image_indices:\n","    test_image = test_images[i]  # Estrai l'immagine di test\n","    true_label = int(test_labels[i])  # Estrai l'etichetta vera\n","\n","    # Effettua la predizione con il modello\n","    prediction = model.predict(np.expand_dims(test_image, axis=0))\n","    predicted_class = prediction.argmax()  # Estrai l'etichetta predetta\n","\n","    labels = {5: 'E', 6: 'S', 7: 'X'} # i numeri non contano perchè sono già in ordine\n","    predicted_label = labels.get(predicted_class, str(predicted_class))\n","\n","    print(\"La predizione è:\", predicted_label)\n","\n","    # Visualizza l'immagine di test\n","    plt.figure()\n","    plt.imshow(test_image.reshape(28, 28), cmap='gray')\n","    true_label = labels.get(true_label, str(true_label))\n","    plt.title(f\"True Label: {true_label}, Predicted Label: {predicted_label}\")\n","    plt.axis('off')\n","    plt.show()"],"metadata":{"id":"noeJK8rcxLrO"},"execution_count":null,"outputs":[]}]}